{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# To specify the site-packages location:\n",
    "import sys\n",
    "sys.path.insert(0, '/home/.conda/envs/tensorflow/lib/python3.6/site-packages')\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "import numpy\n",
    "import tensorflow\n",
    "import keras\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import seaborn\n",
    "\n",
    "import deepometry.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shape(pathname):\n",
    "    return numpy.load(pathname).shape\n",
    "\n",
    "\n",
    "def load(pathnames, labels, patient_to_exclude):\n",
    "\n",
    "    x = numpy.empty((len(pathnames),) + _shape(pathnames[0]), dtype=numpy.uint8)\n",
    "\n",
    "    y = numpy.empty((len(pathnames),), dtype=numpy.uint8)\n",
    "\n",
    "    label_to_index = {label: index for index, label in enumerate(sorted(labels))}\n",
    "\n",
    "    for index, pathname in enumerate(pathnames):\n",
    "        if (os.path.isfile(pathname) == True):\n",
    "\n",
    "            label = os.path.split(os.path.dirname(pathname))[-1]\n",
    "\n",
    "            x[index] = numpy.load(pathname)\n",
    "\n",
    "            y[index] = label_to_index[label]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(directories):\n",
    "\n",
    "    pathnames = []\n",
    "\n",
    "    for directory in directories:\n",
    "        subdirectories = sorted(glob.glob(os.path.join(directory, \"*\")))\n",
    "\n",
    "        subdirectory_pathnames = [glob.glob(os.path.join(subdirectory, \"*\")) for subdirectory in subdirectories]\n",
    "\n",
    "        #nsamples = max([len(pathnames) for pathnames in subdirectory_pathnames])\n",
    "        #nsamples = min([len(pathnames) for pathnames in subdirectory_pathnames])\n",
    "        nsamples = 3000\n",
    "\n",
    "        pathnames += [list(numpy.random.permutation(pathnames)[:nsamples]) for pathnames in subdirectory_pathnames]\n",
    "\n",
    "    pathnames = sum(pathnames, [])\n",
    "\n",
    "    return pathnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: float(majority/count) for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pathnames(directories, labels):\n",
    "\n",
    "    pathnames = []\n",
    "\n",
    "    for directory in directories:\n",
    "        subdirectories = sorted(glob.glob(os.path.join(directory, \"*\")))\n",
    "        \n",
    "        # transform the files of the same label into directory\n",
    "        subdirectory_pathnames = [glob.glob(\"{}/*.npy\".format(subdirectory)) for subdirectory in subdirectories ]      \n",
    "\n",
    "        nsamples = max([len(pathnames) for pathnames in subdirectory_pathnames if '157pres' in pathnames])\n",
    "\n",
    "        pathnames += [list(numpy.random.permutation(pathnames)[:nsamples]) for pathnames in subdirectory_pathnames]\n",
    "\n",
    "    pathnames = sum(pathnames, [])\n",
    "\n",
    "    return pathnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_include(pathnames, labels, patient_to_include):\n",
    "\n",
    "    print('All cells in treated patients: ',len(pathnames))\n",
    "    #pathnames = [x for x in pathnames if patient_to_include in x]\n",
    "    print('Cells in this patient: ',len(pathnames))\n",
    "\n",
    "    x = numpy.empty((len(pathnames),) + _shape(pathnames[0]), dtype=numpy.uint8)\n",
    "\n",
    "    y = numpy.empty((len(pathnames),), dtype=numpy.uint8)\n",
    "\n",
    "    label_to_index = {label: index for index, label in enumerate(sorted(labels))}\n",
    "\n",
    "    for index, pathname in enumerate(pathnames):\n",
    "        if (os.path.isfile(pathname) == True):\n",
    "\n",
    "            label = os.path.split(os.path.dirname(pathname))[-1]\n",
    "\n",
    "            x[index] = numpy.load(pathname)\n",
    "\n",
    "            y[index] = label_to_index[label]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Leukemic\", \"Normal\", \"Others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\"/parsed_data/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(directories)\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patients_to_test = ['157pres','157day8','157day15','171pres','171day11','172pres','172day29','175pres','175day8','177pres','177day8']\n",
    "patients_to_test = ['157pres']\n",
    "selected_to_train = [x for x in samples if numpy.all([not z in x for z in patients_to_test])]\n",
    "\n",
    "len(selected_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata_label(predicted,true,labels,file):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write('Predicted\\tTrue\\n')\n",
    "        for i in range(predicted.shape[0]):              \n",
    "            f.write('{}\\t{}\\n'.format( labels[predicted[i]] , labels[true[i]]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from sklearn import preprocessing\n",
    "import cv2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop 6 channels, what left are bright-field and dark-field\n",
    "\n",
    "for i in [6]:\n",
    "\n",
    "    # build session running on GPU 1\n",
    "    configuration = tensorflow.ConfigProto()\n",
    "    configuration.gpu_options.allow_growth = True\n",
    "    configuration.gpu_options.visible_device_list = \"1\"\n",
    "    session = tensorflow.Session(config = configuration)\n",
    "\n",
    "    # apply session\n",
    "    keras.backend.set_session(session)        \n",
    "  \n",
    "    \n",
    "    for patient_to_test in patients_to_test:\n",
    "\n",
    "        x_test, y_test = load_include(samples, labels, patient_to_test)        \n",
    "\n",
    "        xx = x_test[:,:,:,i:]\n",
    "\n",
    "        #del(x_test)\n",
    "        #x_test = xx\n",
    "        print('Testing : ',patient_to_test)\n",
    "        print(\"Testing set: \", xx.shape)\n",
    "        #del(xx)       \n",
    "\n",
    "        model = deepometry.model.Model(shape=xx.shape[1:], units=len(labels))\n",
    "\n",
    "        model.compile()\n",
    "\n",
    "        model_directory = str('/models/resnet_drop_' + str(i) + '_channels')\n",
    "\n",
    "        model.model.load_weights(os.path.join(model_directory,'model.h5'))      \n",
    "        \n",
    "\n",
    "        predicted = model.predict(\n",
    "            batch_size=50,\n",
    "            x=xx\n",
    "        )\n",
    "\n",
    "        predicted = numpy.argmax(predicted, axis=1)\n",
    "        save_metadata_label(predicted,y_test,labels,'metadata_label_'+patient_to_test+'.tsv')\n",
    "        \n",
    "\n",
    "        layers = model.model.layers\n",
    "        abstract_model = None # Clear cached abstract_model\n",
    "        abstract_model = Sequential([layers[-2]])\n",
    "\n",
    "        extracted_features = abstract_model.predict(\n",
    "            batch_size=50,\n",
    "            x=xx\n",
    "        )\n",
    "        \n",
    "        numpy.save('scaled_features_'+patient_to_test+'.npy' , extracted_features)\n",
    "        # Optional: scale features before saving\n",
    "        #numpy.save('scaled_features_'+patient_to_test+'.npy' , preprocessing.scale(extracted_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.empty((x_test.shape[0],48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,:,:,0] = x_test[:,:,:,0]\n",
    "a[:,:,:,1] = x_test[:,:,:,7]\n",
    "a[:,:,:,2] = x_test[:,:,:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprite = images_to_sprite(a)\n",
    "cv2.imwrite('sprite.png', sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
